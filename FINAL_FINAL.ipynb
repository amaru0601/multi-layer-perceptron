{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "__s6X3Y24Gg_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__s6X3Y24Gg_",
    "outputId": "f6dd47ed-f6fe-4e9d-dc67-5f59bc5c7220"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('mydrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LVM2h5jE5m8-",
   "metadata": {
    "id": "LVM2h5jE5m8-"
   },
   "outputs": [],
   "source": [
    "#!unzip \"mydrive/MyDrive/dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbfc2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05bbfc2f",
    "outputId": "50e68628-cda7-40e8-a670-3e87a8a962e7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import fnmatch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "img_t = transform.Compose([transform.ToTensor()])\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.ImageFolder('dataset/train', transform=img_t)\n",
    "val_set = torchvision.datasets.ImageFolder('dataset/val', transform=img_t)\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ASclO-N9xC3",
   "metadata": {
    "id": "9ASclO-N9xC3"
   },
   "outputs": [],
   "source": [
    "class Low_High_Dataset(Dataset):\n",
    "    def __init__(self, path, tfms):\n",
    "        self.path = Path(path)\n",
    "        self.tfms = tfms\n",
    "        self.len = len(fnmatch.filter(os.listdir(self.path / \"high_res\"), '*.png'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        high_res_path = self.path / \"high_res\" / f\"{idx}.png\"\n",
    "        low_res_path = self.path / \"low_res\" / f\"{idx}.png\"\n",
    "        if self.tfms is not None:\n",
    "            return self.tfms(np.array(Image.open(low_res_path))[...,:-1]), self.tfms(np.array(Image.open(high_res_path))[...,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kKgJCHH5_Nds",
   "metadata": {
    "id": "kKgJCHH5_Nds"
   },
   "outputs": [],
   "source": [
    "train_set = Low_High_Dataset(Path(\"dataset/train\"), img_t)\n",
    "val_set = Low_High_Dataset(Path(\"dataset/val\"), img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfPazDL1_XDu",
   "metadata": {
    "id": "cfPazDL1_XDu"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=2)\n",
    "valid_loader = DataLoader(val_set, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNScPdirEUhg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNScPdirEUhg",
    "outputId": "07e9bd3a-fca7-49f0-c02d-0cc25ca1fb59"
   },
   "outputs": [],
   "source": [
    "l, h = next(iter(train_loader))\n",
    "l.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae299b",
   "metadata": {
    "id": "ebae299b"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=128, kernel_size=7, stride=1, padding=0)\n",
    "    self.pool1 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "    self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=5, stride=1, padding=0)\n",
    "    self.pool2 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "    self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.pool3 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.pool4 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.pool5 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=0)\n",
    "    self.pool6 = nn.MaxPool2d(2, stride = 2, return_indices=True)\n",
    "    self.conv7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "  def forward(self, image):\n",
    "    out1 = F.sigmoid(self.conv1(image))\n",
    "    out1p, ind1 = self.pool1(out1)\n",
    "    out2 = F.sigmoid(self.conv2(out1p))\n",
    "    out2p, ind2 = self.pool2(out2)\n",
    "    out3 = F.sigmoid(self.conv3(out2p))\n",
    "    out3p, ind3 = self.pool3(out3)\n",
    "    out4 = F.sigmoid(self.conv4(out3p))\n",
    "    out4p, ind4 = self.pool4(out4)\n",
    "    out5 = F.sigmoid(self.conv5(out4p))\n",
    "    out5p, ind5 = self.pool5(out5)\n",
    "    out6 = F.sigmoid(self.conv6(out5p))\n",
    "    out6p, ind6 = self.pool6(out6)\n",
    "    out7 = self.conv7(out6p)\n",
    "    z = out7\n",
    "    return z, out1, ind1, out2, ind2, out3, ind3, out4, ind4, out5, ind5, out6, ind6\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.convTran1 = nn.ConvTranspose2d(in_channels=512,out_channels=256, kernel_size=1, stride=1, padding=0)\n",
    "    self.poolT1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran2 = nn.ConvTranspose2d(in_channels=256*2,out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.poolT2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran3 = nn.ConvTranspose2d(in_channels=128*2,out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.poolT3 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran4 = nn.ConvTranspose2d(in_channels=128*2,out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.poolT4 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran5 = nn.ConvTranspose2d(in_channels=128*2,out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "    self.poolT5 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran6 = nn.ConvTranspose2d(in_channels=128*2,out_channels=128, kernel_size=5, stride=1, padding=0)\n",
    "    self.poolT6 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    self.convTran7 = nn.ConvTranspose2d(in_channels=128*2,out_channels=3, kernel_size=7, stride=1, padding=0)\n",
    "    \n",
    "    \n",
    "  def forward(self, latent, out1, ind1, out2, ind2, out3, ind3, out4, ind4, out5, ind5, out6, ind6):\n",
    "    out_1 = self.convTran1(latent)\n",
    "    out_1p = self.poolT1(out_1, ind6, output_size= out6.size())\n",
    "    out_1p = torch.cat([out_1p, out6], 1)\n",
    "    out_2 = F.sigmoid(self.convTran2(out_1p))\n",
    "    out_2p = self.poolT2(out_2, ind5, output_size= out5.size())\n",
    "    out_2p = torch.cat([out_2p, out5], 1)\n",
    "    out_3 = F.sigmoid(self.convTran3(out_2p))\n",
    "    out_3p = self.poolT3(out_3, ind4, output_size=out4.size())\n",
    "    out_3p = torch.cat([out_3p, out4], 1)\n",
    "    out_4 = F.sigmoid(self.convTran4(out_3p))\n",
    "    out_4p = self.poolT4(out_4, ind3)\n",
    "    out_4p = torch.cat([out_4p, out3], 1)\n",
    "    out_5 = F.sigmoid(self.convTran5(out_4p))\n",
    "    out_5p = self.poolT5(out_5, ind2, output_size= out2.size())\n",
    "    out_5p = torch.cat([out_5p, out2], 1)\n",
    "    out_6 = F.sigmoid(self.convTran6(out_5p))\n",
    "    out_6p = self.poolT6(out_6, ind1, output_size= out1.size())\n",
    "    out_6p = torch.cat([out_6p, out1], 1)\n",
    "    out_7 = F.sigmoid(self.convTran7(out_6p))\n",
    "    \n",
    "    return out_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d63e69",
   "metadata": {
    "id": "e2d63e69"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "   def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "   def forward(self, x):\n",
    "        latent, out1, ind1, out2, ind2, out3, ind3, out4, ind4, out5, ind5, out6, ind6 = self.encoder(x)\n",
    "        x_recon = self.decoder(latent, out1, ind1, out2, ind2, out3, ind3, out4, ind4, out5, ind5, out6, ind6)\n",
    "        return  x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76b9e5",
   "metadata": {
    "id": "1c76b9e5"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, Epochs, loss_fn):\n",
    "    train_loss_avg = []\n",
    "    val_loss_avg = []\n",
    "    for epoch in tqdm(range(Epochs)):\n",
    "        train_loss_avg.append(0)\n",
    "        num_batches = 0\n",
    "        for low_res, high_res in train_loader:\n",
    "            high_res, low_res = high_res.cuda(), low_res.cuda()\n",
    "            predicted_high_res = model(low_res)\n",
    "            loss = loss_fn(predicted_high_res, high_res)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "            train_loss_avg[-1] += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        train_loss_avg[-1] /= num_batches\n",
    "        print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, Epochs, train_loss_avg[-1]))\n",
    "\n",
    "        val_loss_avg.append(0)\n",
    "        num_batches=0\n",
    "        for low_res, high_res in val_loader:\n",
    "            with torch.no_grad():\n",
    "                high_res, low_res = high_res.cuda(), low_res.cuda()\n",
    "                predicted_high_res = model(low_res)            \n",
    "                \n",
    "                loss = loss_fn(predicted_high_res, high_res)\n",
    "                val_loss_avg[-1] += loss.item()\n",
    "                num_batches += 1\n",
    "        val_loss_avg[-1] /= num_batches\n",
    "        print('Epoch [%d / %d] average reconstruction validation error: %f' % (epoch+1, Epochs, val_loss_avg[-1]))\n",
    "        \n",
    "        \n",
    "        for low_res, _ in val_loader:\n",
    "          with torch.no_grad(): \n",
    "              high_res, low_res = high_res.cuda(), low_res.cuda()\n",
    "              predicted_high_res = autoencoder(low_res)\n",
    "              #Show_imgs(image_batch[0].cpu(),\"\")\n",
    "              #Show_imgs(image_batch_recon[0].cpu(),\"\")\n",
    "              #image_batch[0].cpu() \n",
    "              im = transform.ToPILImage()(low_res[0]).convert(\"RGB\")  \n",
    "              display(im)\n",
    "              imt = transform.ToPILImage()(predicted_high_res[0]).convert(\"RGB\")\n",
    "              display(imt)\n",
    "              #im = image_batch[0].permute(1,2,0)\n",
    "              #im2 = image_batch_recon[0].permute(1, 2, 0)\n",
    "              #plt.figure()\n",
    "\n",
    "              #plt.imshow(im.cpu())\n",
    "              #plt.figure()\n",
    "              #plt.imshow(im2.cpu().detach().numpy())\n",
    "            # Open Image from dataset:\n",
    "              #my_img = image_batch_recon[0]\n",
    "              #results = transform.ToPILImage()(my_img)\n",
    "              #display(results)\n",
    "              #plt.imshow(image_batch_recon[0].cpu().detach().numpy())  \n",
    "          break\n",
    "        \n",
    "    return train_loss_avg, val_loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee756b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bbee756b",
    "outputId": "0ee6f190-a2b9-4563-a495-8f648ef4eab5"
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "learning_rate = 0.0001\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=autoencoder.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "loss_result, loss_val = train(model=autoencoder, \n",
    "                              train_loader=train_loader,\n",
    "                              val_loader=valid_loader, \n",
    "                              Epochs=epochs, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9d21b",
   "metadata": {
    "id": "c4f9d21b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(loss_result)\n",
    "plt.plot(loss_val)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Reconstruction error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19109b5",
   "metadata": {
    "id": "c19109b5"
   },
   "outputs": [],
   "source": [
    "for low_res, high_res in valid_loader:\n",
    "    with torch.no_grad(): \n",
    "        high_res, low_res = high_res.cuda(), low_res.cuda()\n",
    "        predicted_high_res = autoencoder(low_res)\n",
    "              #Show_imgs(image_batch[0].cpu(),\"\")\n",
    "              #Show_imgs(image_batch_recon[0].cpu(),\"\")\n",
    "              #image_batch[0].cpu() \n",
    "        im = transform.ToPILImage()(low_res[0]).convert(\"RGB\")  \n",
    "        display(im)\n",
    "        imt = transform.ToPILImage()(predicted_high_res[0]).convert(\"RGB\")\n",
    "        display(imt)\n",
    "              #im = image_batch[0].permute(1,2,0)\n",
    "              #im2 = image_batch_recon[0].permute(1, 2, 0)\n",
    "              #plt.figure()\n",
    "\n",
    "              #plt.imshow(im.cpu())\n",
    "              #plt.figure()\n",
    "              #plt.imshow(im2.cpu().detach().numpy())\n",
    "            # Open Image from dataset:\n",
    "              #my_img = image_batch_recon[0]\n",
    "              #results = transform.ToPILImage()(my_img)\n",
    "              #display(results)\n",
    "              #plt.imshow(image_batch_recon[0].cpu().detach().numpy())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9902df40",
   "metadata": {
    "id": "9902df40"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439aaa03",
   "metadata": {
    "id": "439aaa03"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d619afe",
   "metadata": {
    "id": "9d619afe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c58a74",
   "metadata": {
    "id": "34c58a74"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FINAL_FINAL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
